一、引言
在人工智能领域，AI Memory（人工智能记忆）是指模型的记忆机制，帮助AI在处理任务时存储和利用过去的经验、历史信息等。AI Memory通常用于提高任务性能，尤其是在需要长期依赖关系和复杂推理的任务中。本文将探讨几种常见的AI Memory方法以及相关的Python库，分析其优缺点，并讨论不同场景下的适用性。

---

---

---
二、AI记忆优化策略
  AI Memory优化策略旨在提升模型的记忆效率，减少资源消耗，并提高任务处理性能。以下是8种常见的AI记忆优化策略，涵盖从简单的入门方法到复杂的企业级解决方案。

---
1. 基础策略：简单但有效的入门方案
1.1 全量记忆（Full Memory）：不遗忘任何内容
  - 简介：
    - 全量记忆是指将所有输入数据（历史记录、任务状态等）都存储在内存中。模型可以随时访问完整的数据集，进行推理和决策。
  - 优缺点：
    - 优点：
      - 简单易理解，适合小规模数据和短期任务。
      - 保证不会丢失任何信息，适用于需要完全信息的任务。
    - 缺点：
      - 随着数据量的增加，存储需求和计算开销迅速增长，效率低下。
      - 对硬件要求高，尤其是内存限制情况下。
  - 适用场景：
    - 数据量较小或任务时间较短的应用，如在线学习、简单NLP任务等。
1.2 滑动窗口（Sliding Window）
  - 简介：
    - 滑动窗口策略通过限制模型访问的记忆范围，只保存最近一段时间内的数据。这种方法通过窗口的滑动来动态选择保留哪些信息，通常适用于时间序列数据。
  - 优缺点：
    - 优点：
      - 有效控制内存占用，适合需要实时处理的任务。
      - 在长时间序列中，能够更好地处理近期数据的依赖。
    - 缺点：
      - 过时信息可能被丢失，导致模型无法利用全局知识。
      - 窗口大小的选择需要优化，窗口过大或过小都会影响效果。
  - 适用场景：
    - 实时数据处理、时间序列预测、金融市场分析等场景。

---
2. 进阶策略：平衡记忆与性能
2.1 相关性过滤（Relevance Filtering）
  - 简介：
    - 相关性过滤通过根据输入数据与当前任务的相关性来选择性地保存记忆。模型只保留那些与当前任务紧密相关的信息，过滤掉不重要的部分。
  - 优缺点：
    - 优点：
      - 提高内存利用效率，减少冗余信息的存储。
      - 适应性强，能够动态调整记忆内容。
    - 缺点：
      - 过滤策略的设计较为复杂，需要明确的相关性度量标准。
      - 可能导致有用信息的丢失，尤其是在任务复杂或多样性高的情况下。
  - 适用场景：
    - 高维数据分析、自然语言处理、推荐系统等需要选择性记忆的任务。
2.2 摘要压缩（Summary Compression）
  - 简介：
    - 摘要压缩通过对历史数据进行信息压缩，提取关键特征并生成简化版本，从而降低存储需求。这些简化的信息代表了完整数据的核心要素。
  - 优缺点：
    - 优点：
      - 大幅降低内存占用，提升计算效率。
      - 适用于长时间序列和大数据集，能够保留核心信息。
    - 缺点：
      - 压缩过程可能导致信息丢失，影响模型性能。
      - 摘要的生成和压缩过程需要额外的计算开销。
  - 适用场景：
    - 长序列数据处理、大规模图像处理、日志分析等。

---
3. 企业级解决方案
3.1 向量数据库（Vector DB）
  - 简介：
    - 向量数据库通过将数据映射为向量并将这些向量存储在数据库中，实现高效的相似性检索。它允许快速存取与当前查询最相关的信息，适合大规模数据集的管理。
  - 优缺点：
    - 优点：
      - 高效的向量检索和相似度计算，适用于大规模数据的存储和快速查询。
      - 支持分布式计算，能够处理海量数据。
    - 缺点：
      - 需要高效的向量化技术和存储策略，计算复杂度高。
      - 对内存和存储的要求较高，尤其在处理非常大的数据集时。
  - 适用场景：
    - 大规模推荐系统、图像识别、搜索引擎、NLP任务等。
3.2 知识图谱（Knowledge Graph）
  - 简介：
    - 知识图谱通过构建实体与实体之间的关系图，帮助系统将信息以结构化的方式进行存储。这些图谱能够支持推理和查询，提供深层次的语义信息。
  - 优缺点：
    - 优点：
      - 提供丰富的语义信息，有助于模型理解复杂的关系和推理任务。
      - 支持多种类型的数据集成，能够处理异构数据源。
    - 缺点：
      - 构建和维护知识图谱的成本较高，尤其是在信息变化频繁的场景中。
      - 知识图谱的推理能力有限，依赖于图谱构建的质量。
  - 适用场景：
    - 企业知识管理、智能搜索、问答系统等需要结构化知识的任务。

---
4. 前沿混合架构
4.1 分层记忆（Hierarchical Memory）
  - 简介：
    - 分层记忆通过创建多个不同层次的记忆结构，每个层次存储不同粒度的信息。这些层次化的记忆结构可以帮助模型处理多层次的知识。
  - 优缺点：
    - 优点：
      - 有助于组织和存储不同类型的记忆信息，提高记忆和查询的效率。
      - 支持复杂任务的分解与处理，提高推理能力。
    - 缺点：
      - 模型复杂度较高，训练和优化困难。
      - 需要精确设计层次结构，以确保高效存储和访问。
  - 适用场景：
    - 需要多层次推理的任务，如长篇文章的阅读理解、复杂推理任务等。
4.2 类OS内存管理（OS-style Swap）
  - 简介：
    - 类OS内存管理通过动态分配和交换记忆内容来优化内存使用。类似操作系统的内存交换机制，模型根据需求将部分记忆从内存中转移到存储设备，必要时再重新加载。
  - 优缺点：
    - 优点：
      - 提高内存使用效率，能够处理更大规模的任务。
      - 动态调整记忆的存储和访问，适应变化的任务需求。
    - 缺点：
      - 数据交换过程可能导致延迟，影响实时性能。
      - 需要有效的内存管理策略，避免频繁的交换操作带来性能下降。
  - 适用场景：
    - 大规模数据处理、需要动态记忆管理的任务，如深度学习训练、超大规模推荐系统等。

---

---

---
三、AI Memory 框架（开源）
前提：当前 AI Memory系统的核心问题：
- 不管是传统的 RAG 框架还是像 MemGPT 这样的系统，都存在明显短板：
  - 只能处理静态数据：大部分系统只能检索固定文档，面对持续更新的对话、实时变化的业务数据束手无策
  - 时间感知缺失：无法处理「时效性信息」，比如 "客户上个月喜欢 A 产品，这个月换成 B 产品" 这类动态变化
  - 上下文窗口限制：长对话内容塞不进模型的上下文窗口，要么丢信息，要么响应慢到让人崩溃
  - 信息整合能力弱：跨会话、跨时间的信息串联困难，比如 "把客户半年前提的需求和现在的订单关联分析"

---
1. Zep：
github 地址：https://github.com/getzep/zep
论文名称：A Temporal Knowledge Graph Architecture for Agent Memory
论文地址：https://arxiv.org/pdf/2501.13956
1.1 介绍：
- 为了提升动态知识整合的能力，研究团队提出了Zep，一个基于时间感知知识图谱的智能体记忆层服务
- Zep通过动态整合非结构化对话数据和结构化业务数据，解决了现有RAG方法中的静态文档检索问题
- Zep 由 Graphiti 提供支持，这是一个开源时间知识图谱框架，自动构建context的知识图谱，这是将KG应用到了Agent中的一种路径
1.2 试图解决的问题：
- 简单说，Zep 给 AI 装上了一套动态、长效、带时间感知的「记忆系统」，具体解决了三个核心痛点：
  - 动态知识整合：既能吸收聊天记录这类非结构化数据，又能融合业务表格等结构化数据，还能自动更新旧信息
  - 时间维度管理：精准记录 "信息何时有效" 和 "信息何时存入"，轻松处理 "过去 vs 现在" 的关系变化
  - 高效检索能力：在海量历史数据中快速找到最相关的信息，不用把所有内容都塞进上下文窗口
1.3 LangChain 中Zep检索器使用文档：
  - Zep开源：https://python.langchain.ac.cn/docs/integrations/retrievers/zep_memorystore/
  - Zep云：https://python.langchain.ac.cn/docs/integrations/retrievers/zep_cloud_memorystore/
1.4 详情x
Graphiti 引擎：Zep 的核心是它的 Graphiti 引擎，一个带时间感知的动态知识图谱，里面藏着几个关键创新：
1.4.1 三层知识结构
- 底层（Episode 层）：存原始数据（聊天记录、文本等），保留完整信息不丢失
- 中层（语义实体层）：提取人物、事物等实体，以及它们之间的关系（比如 "张三管理李四"）
- 高层（社区层）：把关联紧密的实体聚类，形成 "市场部团队"" 产品 A 系列 " 这类抽象概念
1.4.2 双时间线模型
- 一条记录事件真实发生的时间（比如 "张三 2023 年 5 月入职"）
- 一条记录信息存入系统的时间（比如 "这条信息是 2023 年 5 月 10 日录入的"）
- 解决了 "信息时效性" 和 "数据审计" 的双重需求
1.4.3 智能冲突处理
- 当新信息和旧信息冲突时（比如 "张三换部门"），自动标记旧信息的失效时间
- 用 LLM 判断信息矛盾，确保最新信息优先，同时保留历史记录可追溯
1.4.4 多维度检索
- 结合语义相似性（找意思相近的内容）、全文匹配（关键词精准定位）和图结构搜索（顺着关系网找关联信息）
- 再通过重排序算法（比如按提及频率、graph 距离）确保结果最相关
1.4.5 评估：
- Deep Memory Retrieval 测试（500 组多轮对话）
- LongMemEval 测试（平均 11.5 万 token 的长对话，企业场景更常见）

---
2. Mem0-Mem0g:
github 地址：https://github.com/mem0ai/mem0
论文名称：Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory 
论文地址：https://arxiv.org/abs/2504.19413
2.1 介绍：
- Mem0（“mem-zero”）通过智能内存层增强 AI 助手和代理，实现个性化的 AI 交互。它记住用户偏好，适应个人需求，并随着时间的推移不断学习，非常适合客户支持聊天机器人、人工智能助手和自主系统。
2.2 试图解决的问题：
- 试图解决LLM在多轮对话中保持长期连贯性的问题，具体来说主要是三方面问题
  - 固定长度上下文窗口的限制
  - 缺乏持久的记忆机制
  - 实际应用中存在的效率低下问题
2.3 Mem0：
- 在接受一对新信息时，从dataset中检索对话的总结S和最近的m条消息，形成一个完整的上下文，在用一个基于LLM的function从新对话中提取一组关键记忆
- 对于这组关键记忆中的每一项，从数据库中检索最像的s个，由LLM决定以下四种操作之一：
  - ADD：如果候选记忆与现有记忆不重复，则添加新的记忆
  - UPDATE：如果候选记忆可以补充现有记忆，则更新现有记忆
  - DELETE：如果候选记忆与现有记忆矛盾，则删除现有记忆
  - NOOP：如果候选记忆不需要修改知识库，则不执行任何操作
图1 mem0
[图片]
2.4 Mem0g：
- 在mem0的基础上加入基于图的记忆表示
- 在提取阶段，用LLM把对话转化为三元组
- 在更新阶段，计算embedding后计算相似节点，根据需要创建新节点或使用已有节点，并加入冲突检测机制，用LLM决定哪些信息无效
[图片]
图2 mem0g（图记忆）
2.5 详情：
2.5.1 记忆提取
- Mem0会通过一个异步摘要生成模块生成并存储一个会话摘要（S）。它的作用是概括整个对话的核心主题，从而为后续的记忆提取提供全局记忆。这个过程并不是一次性的，而是随着对话的进展持续进行更新。
2.5.2 稠密记忆
- 把新消息在“摘要 + 近邻窗口”背景下蒸馏成短小的事实条目，并用LLM决定增删改查操作，保持一致且去冗余。
2.5.3 记忆更新
- 在这个阶段，系统会将刚提取的候选记忆组与现有记忆进行对比，确保它们的一致性并避免冗余。为此，Mem0 首先会检索出与候选记忆语义最相似的若干个现有记忆(向量数据库向量检索)。然后通过function call的形式调用记忆更新工具来更新记忆。工具有4个：
  - ADD（添加）：当不存在语义等价的记忆时，使用 ADD 创建新记忆；
  - UPDATE（更新）：使用 UPDATE 对现有记忆进行补充信息的增强；
  - DELETE（删除）：使用 DELETE 删除与新信息相矛盾的记忆；
  - NOOP（无操作）：当候选事实无需修改知识库时，使用 NOOP。
2.5.4 图记忆（mem0g）：
- 使用LLM把会话信息转成“实体-关系-实体”的三元组，存入图数据库；既能顺着实体领域追问，也能对三元组做语义匹配，适用于时间与关系推理。
2.5.5 评估
- LLM-as-a-Judge（J）：用更强的LLM对答案在事实性、相关性、完整性等维度打分，多次运行取均值 方差，弥补F1/BLEU的词面词频偏好。
- P95延迟：第95百分位的响应时间，更能反应“最慢的一批请求”（最难的一些问题）的体验。LOCOMO数据集每段话约有200个问题，系统对每个问题先做记忆检索再生成答案；论文汇报了这些问题的耗时的有序分布，取第95百分位作为p95

---
3. MemOS：
github 地址：https://github.com/MemTensor/MemOS

论文名称：Memory3: Language Modeling with Explicit Memory 
论文地址：https://arxiv.org/abs/2407.01178

论文名称：MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models 
论文地址：https://arxiv.org/abs/2505.22101

论文名称：MemOS: A Memory OS for AI System 
论文地址：https://arxiv.org/abs/2507.03724
3.1 介绍：
- MemOS 是一种为大语言模型（LLMs）设计的操作系统，旨在为其增强长期记忆能力。通过 MemOS，LLMs 可以存储、检索和管理信息，从而使它们能够进行更加上下文感知、一致性更强且个性化的交互。作者认为当前的 LLM 缺乏系统化的记忆管理能力，只能依赖模型参数（隐式记忆）或临时上下文（显式记忆），这限制了模型在长上下文推理、持续个性化、知识更新等方面的表现。
3.2 试图解决的问题：
- 长程依赖缺失（Long-range Dependency）
模型上下文窗口有限，无法在多轮对话或复杂任务中保持一致性与记忆延续。
- 知识时效性差（Knowledge Evolution）
参数静态导致知识无法及时更新；RAG 虽能检索外部知识，但缺乏生命周期与版本控制。
- 个性化能力不足（Personalization）
模型缺乏跨会话记忆，用户偏好或风格无法被持续保存与调取。
- 跨平台迁移难（Cross-platform Memory Migration）
记忆被封闭在单一系统内，导致“记忆孤岛”，用户在不同应用间无法共享上下文。
3.3 详情
3.3.1 LLM memory 4阶段（论文演进过程）
暂时无法在飞书文档外展示此内容
3.3.2 Mem-training 范式
- 作者将这一阶段作为预训练（Pre-training）和后训练（Post-training）的更进一步的新范式
- 记忆训练（Mem-training）通过持续交互积累和演化记忆，实现模型的长时学习与自进化。
3.3.3 类比OS
暂时无法在飞书文档外展示此内容
3.3.4 MemOS 的核心理念（分层记忆）：
- Plaintext Memory（明文记忆）：外部文本、知识片段；
- Activation Memory（激活记忆）：推理过程中生成的 KV 缓存或中间状态；
- Parameter Memory（参数记忆）：模型权重中固化的知识。
[图片]
图3 三种记忆转化图
3.3.5 评估
- 论文使用 LOCOMO benchmark 对系统进行评估，重点测试了四类推理任务的性能：
  - Single-hop Reasoning（单跳推理）
  - Multi-hop Reasoning（多跳推理）
  - Open-domain QA（开放领域问答）
  - Temporal Reasoning（时间推理）
- 评估指标：
 采用 LLM-Judge Score（由大模型评判的综合指标），用于衡量推理一致性与知识利用度。


---
4. letta（formerly MemGPT）：
github 地址：https://github.com/letta-ai/letta
论文名称：MemGPT: Towards LLMs as Operating Systems
论文地址：https://arxiv.org/abs/2310.08560
4.1 介绍：
- MemGPT 受操作系统中 “虚拟内存”与“分页机制” 的启发，设计了一套 虚拟上下文管理机制，通过在 LLM 的有限上下文（相当于主存）与外部存储（相当于磁盘）之间动态分页，实现了“超长上下文”的效果。
-  MemGPT大致可以理解为是一个位于LLM大模型和用户应用之间的编排层（orchestration layer），其底层基础是LLM大模型，同时对外提供服务接口。在实际使用过程中，memgpt会创建一个agent，该agent可视作为一个状态机（stateful），负责管理（中转、编排、传递）某个用户应用与LLM之间的所有对话内容。
4.2 试图解决的问题：
- 传统 LLM 由于 Transformer 架构的限制，输入上下文长度是固定的。当上下文过长时，计算和显存成本呈 平方级增长 O(n²)，这使得模型难以处理长文档、多轮对话或持续交互。
4.3 详情
[图片]
4.3.1 MemGPT memory基本层次结构
- memory的双层数据存储结构。包含context window（第一层级），以及 archival memory和recall memory（第二层级）。借鉴操作系统的虚拟内存（virtual memory）管理机制，将需要频繁调用的关键数据留存在第一层级，将其它数据保存或备份在第二层级。
- 具备memory编辑管理能力的tool工具。基于LLM的function calling功能，通过预先设计定义的function、以及优化的prompt提示词，为tool工具能力提供了支撑保障。
- Context window
  - System Instruction：提供明确的说明来实现自我引导的编辑和检索，这些说明指导大语言模型（LLM）如何与 MemGPT 内存系统进行交互。这些说明包含两个主要部分：(1) 内存层级及其各自功能的详细描述；(2) 一个函数模式（包含其自然语言描述），系统可以调用该模式来访问或修改其内存。
  - Working Context：也称为Core Memory或In-Context memory，用于保存agent的memory block。在默认模式下（正常对话应用场景），agent会包含两个block，一个是human（保存用户基本信息），一个是persona（保存agent自身角色设定）。随着对话过程的展开，agent会根据自行判断或用户指令，持续补充、修改human和persona block中保存的内容。这部分内容就构成了agent对于用户、及自身情况的基本认知。
  - FIFO Queue：主要是包含最近的对话message记录。实际上，由于context窗口长度限制，定期会将一部分message记录保存到Recall Storage、并且会从context中删除这些记录；此时，memgpt会针对删除的message记录、以及原先的summary（如已存在），生成一个recursive memory。在context窗口中，这部分内容调整最为频繁。
- Archival Storage和Recall Storage
  - Archival Storage：Archival Storage可视作为Core memory的补充，提供了“无限空间“。根据system prompt默认模板设定，Archival Storage定位介于core memory和recall storage之间。个人理解通常是会保存一些相对比较抽象的信息，比如agent根据自己理解总结而获得的一些关于用户的行为习惯、或个人偏好等。
另外，当Core memory预留空间用完时，Archival Storage也可作为一个额外的存储空间。Archival Storage采用embedding向量搜索方式。
  - Recall Storage：存放模型近期需要、但暂时不在主上下文中的信息。可被快速取回。
- Function Exeuctor：负责解析、调度和执行由 LLM 生成的函数指令（function calls），从而让模型具备“自主调用系统功能”的能力。
- Queue Manager：负责控制上下文中的“工作信息”进出顺序；维护有限上下文窗口内的消息队列。
4.3.2 虚拟上下文机制
- 分层记忆系统：MemGPT采用了一个分层的记忆管理系统，模仿了传统操作系统中的内存管理。内部存储分为主上下文（main context）和外部上下文（external context）。前者面向LLM直接访问，后者用于完整历史的存儲。主上下文又细分为系统指令、对话内容和工作内容三部分。
  - 系统指令（system instructions）：是只读的，并且在MemGPT代理程序的生命周期内保持不变。
  - 对话上下文（conversational context）：是只读的，并且有一个特殊的剔除策略（如果队列达到一定大小，会通过递归摘要（recursive summarization）来截断或压缩部分前端）。
  - 工作上下文（working context）：可以通过函数调用由LLM处理器进行写入。
  - 这三个部分的总和不能超过LLM处理器的最大上下文大小。在实践中，会限制对话上下文和工作上下文的大小为一个固定的常数，该常数由处理器的上下文窗口和系统指令的长度决定。因此，MemGPT通过合理划分主上下文，并使用适当的剔除策略，实现了无限上下文记忆的效果。
- 动态数据迁移：这是MemGPT的核心机制。简言之，系统让LLM可以自主地在主上下文和外部上下文之间移动数据,而无需外部干预。
  - 具体来说，MemGPT在LLM的prompt中提供了详细的Function Call说明。这些函数具有预定义的输入和输出格式。在每次推理时，LLM会根据当前上下文，主动调用这些函数来读取或修改记忆。
  - 当LLM需要引用过去的对话内容时，它可以调用搜索回忆存储的函数。该函数会在外部上下文中查找相关信息,并将结果页以明确格式返回到主上下文中。LLM就可以在当前的有限上下文里看到这些信息了。
  - 类似地，LLM也可以主动调用写工作内容的函数,来将重要信息保存到外部上下文中。
  - MemGPT使用解析器来验证和执行LLM生成的函数调用。并将执行结果反馈给LLM，这样可以训练LLM学习和调整自己的记忆策略。
4.3.3 中断机制
- 用户指令中断：
  - 在与MemGPT的交互过程中，用户可以发送特定的指令来改变会话的方向或请求特定的上下文信息。例如，用户可能希望模型回顾之前的某个主题，或者暂时忽略某些信息。
  - 这些指令可以被看作是“中断”，它们使用户能够直接与模型的内部状态交互，实现更为灵活的会话管理。
  - 一个例子：假设用户在与MemGPT讨论天气时突然想知道关于某部电影的信息。用户可以直接发送一个指令如“转到昨天关于《星际穿越》的讨论”。MemGPT会识别这个“中断”，并迅速切换到与该电影相关的上下文。
- 上下文切换：
  - 当用户发出中断指令时，MemGPT需要快速地调整其当前的上下文，以便满足用户的新请求。这就是所谓的“上下文切换”。
  - 例如，继续上面的情景，一旦用户请求回顾关于《星际穿越》的讨论，MemGPT会从其存储的历史上下文中检索该部分，并在当前会话中为用户呈现。
- 中断优先级：
  - 不是所有的中断指令都有相同的优先级。有些请求可能比其他请求更紧迫或更重要。MemGPT通过为每个中断指令分配一个优先级来管理这些请求。
  - 当多个中断请求同时出现时，根据其优先级，MemGPT会决定首先处理哪一个，确保最关键的任务得到优先处理。
  - 例如，用户在与MemGPT的会话中同时发送了两个指令：“告诉我明天的天气”和“请提醒我5分钟后喝水”。尽管这两个指令都是中断，但“请提醒我5分钟后喝水”可能具有更高的优先级，因为它涉及到时间敏感性。
4.3.4 扩展的上下文窗口技术：
- 上下文窗口分段：为了更高效地处理超出其原始上下文窗口的信息，MemGPT将长上下文分段，并在需要时动态地加载它们。
- 优先级排序：MemGPT为上下文中的每一部分分配了一个优先级，基于其与当前交互的相关性。这确保了最相关的信息始终处于快速记忆中，并随时可供访问。
4.3.5 评估
- 多次会话场景：与传统的LLMs相比，MemGPT能够更好地追踪和维持与用户的多次会话，即使在会话之间存在时间间隔。这使得MemGPT可以创建的聊天代理更加人性化，能够记住、反映并随着与用户的长期互动而动态演化。
  - 检索历史信息任务中：当被问到只能依赖过去对话内容的问题时,MemGPT的正确率达到82.4%,明显优于固定上下文的GPT-3.5(55.6%)和GPT-4(79.2%)。MemGPT可以搜索外部存储的完整对话,而GPT只有递归摘要。
  - 生成开场白任务中：配备工作记忆的MemGPT与人类编写的开场白在个性化和相关性上达到了可比性。删除工作记忆后,其性能大幅下降。
- 文档分析：MemGPT在处理超出传统大型语言模型上下文窗口的大型文档时表现出色。这证明了其扩展上下文窗口方法的有效性。
  - 文档阅读问答任务：MemGPT可以处理远超上下文长度限制的文档。而固定上下文模型GPT-3.5和GPT-4的准确率随文档量增长迅速下降。
  - 需要多次检索的嵌套知识库问答：MemGPT正确完成4层检索100%，而GPT-3.5和GPT-4在2层以上基本无法完成任务。

---
5. Cognee：（未读）
  - 简介：结合了RAG和知识图谱的一个库

---

---

---
6. Langgraph
  - 短期记忆
    - 添加
    - 管理
  - 中长期记忆
    - 添加
    - 管理
      - langmem
四、近期的论文
1. memory-R1
论文名称：Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning 
论文地址：https://arxiv.org/abs/2508.19828
1.1 介绍
- 大型语言模型（LLM）在自然语言处理任务中展现了惊人的能力，但其根本上的“无状态”特性和有限的上下文窗口，极大地阻碍了它们进行长时程推理。为了解决这一局限，近期的研究常常为LLM配备一个外部记忆库。然而，现有的大多数方案都是静态和基于启发式的，缺乏一个能通过学习来决定存储、更新或检索什么内容的关键机制。
- 为此，来自慕尼黑大学、慕尼黑工业大学、剑桥大学和香港大学的研究团队提出了 Memory-R1，这是一个创新的强化学习（RL）框架。它通过训练两个专门的智能体，赋予LLM主动管理和利用外部记忆的能力：一个 记忆管理器（Memory Manager），学习执行结构化的记忆操作（增、删、改、查）；以及一个 回答智能体（Answer Agent），负责筛选最相关的记忆条目并基于此进行推理以生成答案。这两个智能体都通过结果驱动的强化学习（PPO和GRPO）进行微调，从而实现了自适应的记忆管理，且整个过程仅需极少的监督。
1.2 试图解决的问题
- 检索挑战：简单的启发式检索要么可能遗漏关键信息，要么可能引入过多无关信息，干扰LLM的判断。
- 管理挑战：更重要的是，记忆库本身如何维护？当新的信息出现时，应该新增（ADD）一条记忆，更新（UPDATE）一条现有记忆，还是删除（DELETE）一条过时或错误的记忆？现有系统大多依赖LLM的“自觉”，缺乏一个为最终结果负责的学习机制。
1.3 详情
1.3.1 Memory Manager（记忆管理器）：
- 通过PPO/GRPO后训练
  - 训练方式：通过强化学习（PPO或GRPO算法）进行训练。在训练中，记忆管理器做出一个操作（如UPDATE），更新记忆库。然后，这个更新后的记忆库被传递给一个（冻结的）回答智能体去回答一个相关问题。最终答案的正确与否，将作为奖励信号反馈给记忆管理器。通过这种“结果导向”的训练，记忆管理器能学会何种操作序列对最终的问答任务最有利，而无需对每一步操作进行人工标注。
- 执行结构化的记忆操作以维护和发展记忆库；
- Memory Manager决定是添加（ADD）、更新（UPDATE）、删除（DELETE）还是无操作（NOOP），从而维护和发展记忆状态。
1.3.2 Answer Agent（答案代理）：
- 通过PPO/GRPO后训练
  - 记忆蒸馏：当面对一个问题时，系统首先通过常规的RAG方法从记忆库中检索出60条可能相关的记忆。但回答智能体并不会直接使用这60条信息，而是会先执行一个“筛选”动作，从中“蒸馏”出真正对回答问题有用的少数几条核心记忆。最后，它仅基于这些经过提纯的、高质量的记忆进行推理和回答。这个“先筛选，后回答”的过程，极大地降低了无关信息的干扰。
  - 训练方式：与记忆管理器类似，回答智能体也通过RL进行端到端训练，奖励信号同样来自最终答案的准确性。
- 应用记忆蒸馏策略来筛选检索到的记忆。
- 在回答问题时，Answer Agent会对检索到的记忆应用记忆蒸馏策略，以过滤噪声并推理最相关的内容。
1.3.3 评估：
- 实验在广泛使用的长时程对话理解基准 LOCOMO 上进行。为了验证框架的通用性，研究团队在 LLaMA-3.1-8B 和 Qwen-2.5-7B 两个不同的LLM基座上进行了测试。评估指标包括F1、BLEU-1以及更侧重语义正确性的LLM-as-a-Judge。


---
2. m3-agent（未读）
介绍：
github地址：https://github.com/ByteDance-Seed/m3-agent
论文名称：Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory
论文地址：https://arxiv.org/abs/2508.09736

3. Rethinking Memory in AI（近期综述，未读）
介绍
论文名称：Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions 
论文地址：https://arxiv.org/abs/2505.00675

4. G- memory
Github 地址：https://github.com/bingreeky/GMemory
论文名称：G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems
论文地址：https://arxiv.org/abs/2506.07398

整理文档地址：G-memory：Tracing Hierarchical Memory for Multi-Agent Systems

---

---

---
五、上下文工程论文
1. ACE
论文名称：Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models
论文地址：https://arxiv.org/pdf/2510.04618v1
整理文档地址：Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models

六 、总结
存储、更新或检索
AI memory主要挑战：
首先进行推理：
1. 核心目标就是怎么基于当前用户提供的内容找到匹配的用户历史信息。
2. 这就涉及到匹配（搜索）以及存储问题
3. 压缩以及相关性过滤可以进一步的优化存储问题
4. 。。。（待补充）
人工智能系统无法在不同会话或上下文溢出后本质上保存信息。
